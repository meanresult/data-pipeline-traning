# Data Pipeline Training  
### Airflow · Snowflake · Docker 기반 데이터 파이프라인 학습 프로젝트

---

## 1. 프로젝트 개요 (Why)

이 저장소는 **국비 교육 과정에서 데이터 엔지니어링을 학습하던 중**,  
수업에서 다루는 개념만으로는 실제 데이터 파이프라인의 구조와 운영 방식을 충분히 이해하기 어렵다고 느껴  
개인적으로 **추가 학습과 실습을 통해 정리한 데이터 파이프라인 학습 프로젝트**입니다.

단순한 도구 사용법 습득이 아니라,

- 데이터가 어디에서 생성되고
- 어떤 과정을 거쳐 정제·적재되며
- 왜 자동화와 재실행 가능성이 중요한지

를 **직접 구성하고 시행착오를 겪으며 이해하는 것**을 목표로 했습니다.

---

## 2. 학습 배경과 문제의식

국비 교육 과정 중 다음과 같은 질문을 스스로에게 던지게 되었습니다.

- Airflow는 단순한 스케줄러일까, 아니면 데이터 흐름을 관리하는 도구일까?
- Snowflake에 데이터를 적재할 때 왜 단순 `INSERT`가 아닌 배치 적재와 `MERGE` 구조가 필요한가?
- Docker는 개발 편의를 위한 도구일까, 아니면 운영을 고려한 필수 요소일까?

이 프로젝트는 위 질문들에 대해  
**문서로 이해한 답이 아니라, 직접 구현하고 수정하며 얻은 이해를 정리한 결과물**입니다.

---

## 3. 사용 기술 스택 (Tech Stack)

### 데이터 파이프라인 / 오케스트레이션
- **Apache Airflow**
  - DAG 기반 작업 흐름 정의
  - 태스크 의존성 관리
  - 재실행 가능한 파이프라인 구조 설계

### 데이터 웨어하우스
- **Snowflake**
  - Raw / Staging / Mart 개념 이해
  - 배치 적재 구조 설계
  - `MERGE` 기반 Upsert 처리

### 실행 환경
- **Docker / Docker Compose**
  - 로컬 환경에서도 재현 가능한 실행 환경 구성
  - 환경 차이로 인한 오류 최소화

### 기타
- Python
- SQL
- Git / GitHub (버전 관리 및 학습 기록)

---

## 4. 프로젝트에서 중점적으로 학습한 내용

### 1️⃣ 운영 가능한 파이프라인 구조
- 한 번 실행되고 끝나는 코드가 아닌  
  **실패 시 재실행 가능한 파이프라인 구조**에 대한 이해
- 동일 DAG 재실행 시 결과가 달라지지 않도록 설계

### 2️⃣ 데이터 흐름 단계 분리
- Raw → Staging → Mart 구조를 직접 적용
- 각 단계의 역할을 분리하여
  - 오류 추적
  - 데이터 검증
  - 재처리 가능성
  을 고려한 구조 설계 경험

### 3️⃣ Git을 학습 기록 도구로 활용
- 결과물보다 **사고 과정과 구조 변화**를 커밋 단위로 기록
- 협업과 유지보수를 고려한 버전 관리 방식 학습

---

## 5. 프로젝트를 통해 얻은 역량

이 프로젝트를 통해 다음과 같은 역량을 키웠습니다.

- 데이터 파이프라인의 전체 흐름을 **구조적으로 설명할 수 있는 이해도**
- 단일 기술이 아닌, **여러 도구가 함께 사용되는 이유에 대한 맥락적 이해**
- 오류와 환경 문제를 겪으며 **문제를 단계적으로 분해하고 해결하는 사고 방식**
- 설계 선택에 대해 **“왜 이렇게 했는지”를 설명할 수 있는 경험**

---

## 6. 앞으로의 목표

이 프로젝트는 완성형 결과물이 아니라  
**데이터 엔지니어로 성장하기 위한 학습 기록의 출발점**입니다.

앞으로는 다음과 같은 방향으로 확장하고자 합니다.

- 다양한 데이터 소스를 활용한 파이프라인 확장
- 데이터 품질 검증 단계 고도화
- 로그 및 모니터링 관점에서의 파이프라인 개선
- 팀 단위 협업을 가정한 구조 설계 경험 축적

---

## 7. 제가 할 수 있는 일

이 프로젝트를 통해 다음과 같은 역할을 수행할 수 있는 기반을 갖추고자 합니다.

- 데이터 수집 → 정제 → 적재 흐름을 이해하고 설명할 수 있는 **주니어 데이터 엔지니어**
- 기존 파이프라인을 읽고 구조를 파악하며 **개선 포인트를 고민할 수 있는 역할**
- 기술을 단순 사용이 아닌 **이유부터 학습하는 태도**

---

## 8. 마무리

이 저장소는  
“이미 완성된 전문가의 결과물”이 아니라  
**실무를 이해하기 위해 고민하고 시도한 과정의 기록**입니다.

데이터 엔지니어링을  
기술 나열이 아닌 **문제 해결을 위한 구조적 사고**로 접근하며  
지속적으로 성장하고자 합니다.
